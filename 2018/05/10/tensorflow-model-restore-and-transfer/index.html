<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="记性越来越差，只能把学过的东西记下来，不然白学"><title>TensorFlow的模型恢复与迁移 | 老姜工作室</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">TensorFlow的模型恢复与迁移</h1><a id="logo" href="/.">老姜工作室</a><p class="description">数据挖掘 | 编程 | 学习笔记</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">TensorFlow的模型恢复与迁移</h1><div class="post-meta">May 10, 2018<span> | </span><span class="category"><a href="/categories/tensorflow/">tensorflow</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#TensorFlow的模型恢复与迁移"><span class="toc-number">1.</span> <span class="toc-text">TensorFlow的模型恢复与迁移</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-TensorFlow模型文件"><span class="toc-number">1.1.</span> <span class="toc-text">1 TensorFlow模型文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-保存Tensorflow模型"><span class="toc-number">1.2.</span> <span class="toc-text">2 保存Tensorflow模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-保存指定的变量、op"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 保存指定的变量、op</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-导入训练好的模型"><span class="toc-number">1.3.</span> <span class="toc-text">3 导入训练好的模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-构造网络图"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 构造网络图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-加载参数"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 加载参数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-使用恢复的模型"><span class="toc-number">1.4.</span> <span class="toc-text">4 使用恢复的模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-加入一些新的layers"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1 加入一些新的layers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-只想恢复图的一部分，并且再加入其它的op用于fine-tuning"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2 只想恢复图的一部分，并且再加入其它的op用于fine-tuning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#通过常量的方式保存于一个文件中"><span class="toc-number">1.5.</span> <span class="toc-text">通过常量的方式保存于一个文件中</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Part8-通过convert-variables-to-constants函数将计算图中的变量及其取值通过常量的方式保存于一个文件中"><span class="toc-number">2.</span> <span class="toc-text">Part8: 通过convert_variables_to_constants函数将计算图中的变量及其取值通过常量的方式保存于一个文件中</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Part9-载入包含变量及其取值的模型"><span class="toc-number">3.</span> <span class="toc-text">Part9: 载入包含变量及其取值的模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#链接"><span class="toc-number">3.1.</span> <span class="toc-text">链接</span></a></li></ol></li></ol></div></div><div class="post-content"><h1 id="TensorFlow的模型恢复与迁移"><a href="#TensorFlow的模型恢复与迁移" class="headerlink" title="TensorFlow的模型恢复与迁移"></a>TensorFlow的模型恢复与迁移</h1><h2 id="1-TensorFlow模型文件"><a href="#1-TensorFlow模型文件" class="headerlink" title="1 TensorFlow模型文件"></a>1 TensorFlow模型文件</h2><p>目录结构：</p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">|<span class="string">--checkpoint_dir</span></div><div class="line">|<span class="string">    </span>|<span class="string">--checkpoint</span></div><div class="line">|<span class="string">    </span>|<span class="string">--MyModel.meta</span></div><div class="line">|<span class="string">    </span>|<span class="string">--MyModel.data-00000-of-00001</span></div><div class="line">|<span class="string">    </span>|<span class="string">--MyModel.index</span></div></pre></td></tr></table></figure>
<ul>
<li>MyModel.meta文件保存的是图结构，meta文件是pb（protocol buffer）格式文件，包含变量、op、集合等。</li>
<li>ckpt文件是二进制文件，保存了所有的weights、biases、gradients等变量。在tensorflow 0.11之前，保存在.ckpt文件中。0.11后，通过两个文件保存MyModel.data-00000-of-00001 与 MyModel.index。（不需要再加ckpt后缀）</li>
<li>checkpoint_dir目录下还有checkpoint文件，该文件是个文本文件，里面记录了保存的最新的checkpoint文件以及其它checkpoint文件列表。在inference（调用）时，可以通过修改这个文件，指定使用哪个model。</li>
</ul>
<h2 id="2-保存Tensorflow模型"><a href="#2-保存Tensorflow模型" class="headerlink" title="2 保存Tensorflow模型"></a>2 保存Tensorflow模型</h2><p>tensorflow 提供了tf.train.Saver类来保存模型，值得注意的是，在tensorflow中，变量是存在于Session环境中，也就是说，只有在Session环境下才会存有变量值，因此，保存模型时需要传入session：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">saver = tf<span class="selector-class">.train</span><span class="selector-class">.Saver</span>()</div><div class="line">saver.save(sess,<span class="string">"./checkpoint_dir/MyModel"</span>)</div></pre></td></tr></table></figure>
<p>执行后，在checkpoint_dir目录下创建模型文件如下：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">checkpoint</div><div class="line">MyModel<span class="selector-class">.data-00000-of-00001</span></div><div class="line">MyModel<span class="selector-class">.index</span></div><div class="line">MyModel.meta</div></pre></td></tr></table></figure>
<p>另外，如果想要在1000次迭代后，再保存模型，只需设置global_step参数即可：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">saver</span><span class="selector-class">.save</span>(sess, <span class="string">'./checkpoint_dir/MyModel'</span>,global_step=<span class="number">1000</span>)</div></pre></td></tr></table></figure>
<p>如果保存多个模型，但由于图是不变的，没必要每次都去保存，可以通过如下方式指定不保存图：</p>
<figure class="highlight autoit"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">saver.save(sess, <span class="string">'./checkpoint_dir/MyModel'</span>,global_step=<span class="keyword">step</span>,write_meta_graph=<span class="literal">False</span>)</div></pre></td></tr></table></figure>
<p>另一种比较实用的是，如果你希望每2小时保存一次模型，并且只保存最近的5个模型文件：<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.train.Saver(<span class="attribute">max_to_keep</span>=5, <span class="attribute">keep_checkpoint_every_n_hours</span>=2)</div></pre></td></tr></table></figure></p>
<h3 id="2-1-保存指定的变量、op"><a href="#2-1-保存指定的变量、op" class="headerlink" title="2.1 保存指定的变量、op"></a>2.1 保存指定的变量、op</h3><p>如果我们不对tf.train.Saver指定任何参数，默认会保存所有变量。如果你不想保存所有变量，而只保存一部分变量，可以通过指定variables/collections。在创建tf.train.Saver实例时，通过将需要保存的变量构造list或者dictionary，传入到Saver中：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">import tensorflow <span class="keyword">as</span> <span class="keyword">tf</span></div><div class="line">w1 = <span class="keyword">tf</span>.Variable(<span class="keyword">tf</span>.random_normal(shape=[<span class="number">2</span>]), name=<span class="string">'w1'</span>)</div><div class="line">w2 = <span class="keyword">tf</span>.Variable(<span class="keyword">tf</span>.random_normal(shape=[<span class="number">5</span>]), name=<span class="string">'w2'</span>)</div><div class="line">saver = <span class="keyword">tf</span>.train.Saver([w1,w2])</div><div class="line">sess = <span class="keyword">tf</span>.Session()</div><div class="line">sess.run(<span class="keyword">tf</span>.global_variables_initializer())</div><div class="line">saver.save(sess, <span class="string">'./checkpoint_dir/MyModel'</span>,global_step=<span class="number">1000</span>)</div></pre></td></tr></table></figure>
<h2 id="3-导入训练好的模型"><a href="#3-导入训练好的模型" class="headerlink" title="3 导入训练好的模型"></a>3 导入训练好的模型</h2><p>在第1小节中我们介绍过，tensorflow将<strong>图</strong>和<strong>变量数据</strong>分开保存为不同的文件。因此，在导入模型时，也要分为2步：</p>
<ol>
<li>构造网络图</li>
<li>加载参数</li>
</ol>
<h3 id="3-1-构造网络图"><a href="#3-1-构造网络图" class="headerlink" title="3.1 构造网络图"></a>3.1 构造网络图</h3><p>两种方法：</p>
<ul>
<li>可以手动敲代码，实现跟原来模型一模一样的图结构（注意：变量名要相同）；</li>
<li>最好的方法是，既然已经保存了图，直接导入图就可以了，那就没必要在去手写一次图结构代码。</li>
</ul>
<p>如果加载了以前的模型，那么模型中定义的常量就无法修改了例如学习率等，那么就可以直接用原来的代码。如果在原来基础上继续训练那么restore的时候继续使用储存时的saver。</p>
<p>加载保存的图：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">saver=tf<span class="selector-class">.train</span><span class="selector-class">.import_meta_graph</span>(<span class="string">'./checkpoint_dir/MyModel-1000.meta'</span>)</div></pre></td></tr></table></figure>
<p>当你恢复一个元检查点时，实际上是将保存的图加载到当前默认的图中。现在你可以通过它来加载任何包含的内容，如张量、操作或集合。</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line"><span class="comment"># Let's load a previously saved meta graph in the default graph</span></div><div class="line"></div><div class="line"><span class="comment"># This function returns a Saver</span></div><div class="line"></div><div class="line">saver = tf.train.import_meta_graph('results/model.ckpt-1000.meta')</div><div class="line"></div><div class="line"><span class="comment"># We can now access the default graph where all our metadata has been loaded</span></div><div class="line"></div><div class="line">graph = tf.get_default_graph()</div><div class="line"></div><div class="line"><span class="comment"># Finally we can retrieve tensors, operations, collections, etc.</span></div><div class="line"></div><div class="line">global_step_tensor = graph.get_tensor_by_name('loss/global_step:0')</div><div class="line"></div><div class="line">train_op = graph.get_operation_by_name('loss/train_op')</div><div class="line"></div><div class="line">hyperparameters = tf.get_collection('hyperparameters')</div></pre></td></tr></table></figure>
<h3 id="3-2-加载参数"><a href="#3-2-加载参数" class="headerlink" title="3.2 加载参数"></a>3.2 加载参数</h3><p>仅仅有图并没有用，更重要的是，我们需要前面训练好的模型参数（即weights、biases等），本文第2节提到过，<strong>变量值需要依赖于Session</strong>，因此在加载参数时，先要构造好Session：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">import tensorflow <span class="keyword">as</span> <span class="keyword">tf</span></div><div class="line">with <span class="keyword">tf</span>.Session() <span class="keyword">as</span> ses<span class="variable">s:</span></div><div class="line">  new_saver = <span class="keyword">tf</span>.train.import_meta_graph(<span class="string">'./checkpoint_dir/MyModel-1000.meta'</span>)</div><div class="line">  new_saver.restore(sess, <span class="keyword">tf</span>.train.latest_checkpoint(<span class="string">'./checkpoint_dir'</span>))</div></pre></td></tr></table></figure>
<p>此时，W1和W2加载进了图，并且可以被访问：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">import tensorflow <span class="keyword">as</span> <span class="keyword">tf</span></div><div class="line">with <span class="keyword">tf</span>.Session() <span class="keyword">as</span> ses<span class="variable">s:</span>    </div><div class="line">    saver = <span class="keyword">tf</span>.train.import_meta_graph(<span class="string">'./checkpoint_dir/MyModel-1000.meta'</span>)</div><div class="line">    saver.restore(sess,<span class="keyword">tf</span>.train.latest_checkpoint(<span class="string">'./checkpoint_dir'</span>))</div><div class="line">    <span class="keyword">print</span>(sess.run(<span class="string">'w1:0'</span>))</div><div class="line">##Model <span class="built_in">has</span> been restored. Above statement will <span class="keyword">print</span> the saved value</div></pre></td></tr></table></figure>
<p>latetst_checkpoint 会读取目录下的checkpoint文件，然后返回最新的一个model变量值。</p>
<p>也可以这样操作，指定恢复的变量，理解恢复操作的最好方法是将其简单地当作一种初始化。</p>
<figure class="highlight 1c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">saver.restore(sess, 'results/model.ckpt.data-<span class="number">1000-0000</span>0-of-<span class="number">0000</span>1')</div></pre></td></tr></table></figure>
<h2 id="4-使用恢复的模型"><a href="#4-使用恢复的模型" class="headerlink" title="4 使用恢复的模型"></a>4 使用恢复的模型</h2><p>前面我们理解了如何保存和恢复模型，很多时候，我们希望使用一些已经训练好的模型，如prediction、fine-tuning以及进一步训练等。这时候，我们可能需要获取训练好的模型中的一些中间结果值，可以通过graph.get_tensor_by_name(‘w1:0’)来获取，注意w1:0是tensor的name。</p>
<p>假设我们有一个简单的网络模型，代码如下：</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line"></div><div class="line">w1 = tf.placeholder(<span class="string">"float"</span>, name=<span class="string">"w1"</span>)</div><div class="line">w2 = tf.placeholder(<span class="string">"float"</span>, name=<span class="string">"w2"</span>)</div><div class="line">b1= tf.Variable(2.0,name=<span class="string">"bias"</span>) </div><div class="line"></div><div class="line"><span class="comment">#定义一个op，用于后面恢复</span></div><div class="line">w3 = tf.add(w1,w2)</div><div class="line">w4 = tf.multiply(w3,b1,name=<span class="string">"op_to_restore"</span>)</div><div class="line">sess = tf.Session()</div><div class="line">sess.run(tf.global_variables_initializer())</div><div class="line"></div><div class="line"><span class="comment">#创建一个Saver对象，用于保存所有变量</span></div><div class="line">saver = tf.train.Saver()</div><div class="line"></div><div class="line"><span class="comment">#通过传入数据，执行op</span></div><div class="line">print(sess.run(w4,feed_dict =&#123;w1:4,w2:8&#125;))</div><div class="line"><span class="comment">#打印 24.0 ==&gt;(w1+w2)*b1</span></div><div class="line"></div><div class="line"><span class="comment">#现在保存模型</span></div><div class="line">saver.save(sess, './checkpoint_dir/MyModel',global_step=1000)</div></pre></td></tr></table></figure>
<p>接下来我们使用<code>graph.get_tensor_by_name()</code>方法来操纵这个保存的模型。</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">sess=tf.Session()</div><div class="line"><span class="comment">#先加载图和参数变量</span></div><div class="line">saver = tf.train.import_meta_graph('./checkpoint_dir/MyModel-1000.meta')</div><div class="line">saver.restore(sess, tf.train.latest_checkpoint('./checkpoint_dir'))</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 访问placeholders变量，并且创建feed-dict来作为placeholders的新值</span></div><div class="line">graph = tf.get_default_graph()</div><div class="line">w1 = graph.get_tensor_by_name(<span class="string">"w1:0"</span>)</div><div class="line">w2 = graph.get_tensor_by_name(<span class="string">"w2:0"</span>)</div><div class="line">feed_dict =&#123;w1:13.0,w2:17.0&#125;</div><div class="line"></div><div class="line"><span class="comment">#接下来，访问你想要执行的op</span></div><div class="line">op_to_restore = graph.get_tensor_by_name(<span class="string">"op_to_restore:0"</span>)</div><div class="line"></div><div class="line">print(sess.run(op_to_restore,feed_dict))</div><div class="line"><span class="comment">#打印结果为60.0==&gt;(13+17)*2</span></div></pre></td></tr></table></figure>
<h3 id="4-1-加入一些新的layers"><a href="#4-1-加入一些新的layers" class="headerlink" title="4.1 加入一些新的layers"></a>4.1 加入一些新的layers</h3><figure class="highlight makefile"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line"><span class="comment"># 先加载图和变量</span></div><div class="line">saver = tf.train.import_meta_graph('my_test_model-1000.meta')</div><div class="line">saver.restore(sess, tf.train.latest_checkpoint('./'))</div><div class="line"></div><div class="line"><span class="comment"># 访问placeholders变量，并且创建feed-dict来作为placeholders的新值</span></div><div class="line">graph = tf.get_default_graph()</div><div class="line">w1 = graph.get_tensor_by_name(<span class="string">"w1:0"</span>)</div><div class="line">w2 = graph.get_tensor_by_name(<span class="string">"w2:0"</span>)</div><div class="line">feed_dict = &#123;w1: 13.0, w2: 17.0&#125;</div><div class="line"></div><div class="line"><span class="comment">#接下来，访问你想要执行的op</span></div><div class="line">op_to_restore = graph.get_tensor_by_name(<span class="string">"op_to_restore:0"</span>)</div><div class="line"></div><div class="line"><span class="comment"># 在当前图中能够加入op</span></div><div class="line">add_on_op = tf.multiply(op_to_restore, 2)</div><div class="line"></div><div class="line">print (sess.run(add_on_op, feed_dict))</div><div class="line"><span class="comment"># 打印120.0==&gt;(13+17)*2*2</span></div></pre></td></tr></table></figure>
<h3 id="4-2-只想恢复图的一部分，并且再加入其它的op用于fine-tuning"><a href="#4-2-只想恢复图的一部分，并且再加入其它的op用于fine-tuning" class="headerlink" title="4.2 只想恢复图的一部分，并且再加入其它的op用于fine-tuning"></a>4.2 只想恢复图的一部分，并且再加入其它的op用于fine-tuning</h3><p>如果只想恢复图的一部分，并且再加入其它的op用于fine-tuning。只需通过graph.get_tensor_by_name()方法获取需要的op，并且在此基础上建立图，看一个简单例子，假设我们需要在训练好的VGG网络使用图，并且修改最后一层，将输出改为2，用于fine-tuning新数据：</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">saver = tf.train.import_meta_graph('vgg.meta')</div><div class="line"><span class="comment"># 访问图</span></div><div class="line">graph = tf.get_default_graph() </div><div class="line"></div><div class="line"><span class="comment">#访问用于fine-tuning的output</span></div><div class="line">fc7= graph.get_tensor_by_name('fc7:0')</div><div class="line"></div><div class="line"><span class="comment">#如果你想修改最后一层梯度，需要如下</span></div><div class="line">fc7 = tf.stop_gradient(fc7) <span class="comment"># It's an identity function</span></div><div class="line">fc7_shape= fc7.get_shape().as_list()</div><div class="line"></div><div class="line">new_outputs=2</div><div class="line">weights = tf.Variable(tf.truncated_normal([fc7_shape[3], num_outputs], stddev=0.05))</div><div class="line">biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))</div><div class="line">output = tf.matmul(fc7, weights) + biases</div><div class="line">pred = tf.nn.softmax(output)</div><div class="line"></div><div class="line"><span class="comment"># Now, you run this with fine-tuning data in sess.run()</span></div></pre></td></tr></table></figure>
<h2 id="通过常量的方式保存于一个文件中"><a href="#通过常量的方式保存于一个文件中" class="headerlink" title="通过常量的方式保存于一个文件中"></a>通过常量的方式保存于一个文件中</h2><h1 id="Part8-通过convert-variables-to-constants函数将计算图中的变量及其取值通过常量的方式保存于一个文件中"><a href="#Part8-通过convert-variables-to-constants函数将计算图中的变量及其取值通过常量的方式保存于一个文件中" class="headerlink" title="Part8: 通过convert_variables_to_constants函数将计算图中的变量及其取值通过常量的方式保存于一个文件中"></a>Part8: 通过convert_variables_to_constants函数将计算图中的变量及其取值通过常量的方式保存于一个文件中</h1><p>import tensorflow as tf<br>from tensorflow.python.framework import graph_util  </p>
<p>v1 = tf.Variable(tf.constant(1.0, shape=[1]), name=”v1”)<br>v2 = tf.Variable(tf.constant(2.0, shape=[1]), name=”v2”)<br>result = v1 + v2  </p>
<p>with tf.Session() as sess:<br>    sess.run(tf.global_variables_initializer())  </p>
<pre><code># 导出当前计算图的GraphDef部分，即从输入层到输出层的计算过程部分  
graph_def = tf.get_default_graph().as_graph_def()  
output_graph_def = graph_util.convert_variables_to_constants(sess,  
                                                    graph_def, [&apos;add&apos;])  

with tf.gfile.GFile(&quot;Model/combined_model.pb&quot;, &apos;wb&apos;) as f:  
    f.write(output_graph_def.SerializeToString())  
</code></pre><h1 id="Part9-载入包含变量及其取值的模型"><a href="#Part9-载入包含变量及其取值的模型" class="headerlink" title="Part9: 载入包含变量及其取值的模型"></a>Part9: 载入包含变量及其取值的模型</h1><p>import tensorflow as tf<br>from tensorflow.python.platform import gfile  </p>
<p>with tf.Session() as sess:<br>    model_filename = “Model/combined_model.pb”<br>    with gfile.FastGFile(model_filename, ‘rb’) as f:<br>        graph_def = tf.GraphDef()<br>        graph_def.ParseFromString(f.read())  </p>
<pre><code>result = tf.import_graph_def(graph_def, return_elements=[&quot;add:0&quot;])  
print(sess.run(result)) # [array([ 3.], dtype=float32)]  
</code></pre><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><ul>
<li><a href="http://blog.csdn.net/huachao1001/article/details/78501928" target="_blank" rel="external">http://blog.csdn.net/huachao1001/article/details/78501928</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/25906127" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/25906127</a></li>
<li>Graph和Session: <a href="http://blog.csdn.net/xierhacker/article/details/53860379" target="_blank" rel="external">http://blog.csdn.net/xierhacker/article/details/53860379</a></li>
</ul>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://zhiqiang.studio/2018/05/10/tensorflow-model-restore-and-transfer/" data-id="cjhu93bzv0083zlhw67l7jcea" class="article-share-link">分享</a><div class="tags"><a href="/tags/tensorflow/">tensorflow</a></div><div class="post-nav"><a href="/2018/05/11/python-unittest/" class="pre">python-unittest</a><a href="/2018/05/09/python-Multiprocessing/" class="next">python-Multiprocessing</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Leetcode刷题/">Leetcode刷题</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Matlab/">Matlab</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/R语言/">R语言</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/matplotlib/">matplotlib</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/py/">py</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/sklearn/">sklearn</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tensorflow/">tensorflow</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/自然语言处理/">自然语言处理</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a><span class="category-list-count">2</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/工作流程/" style="font-size: 15px;">工作流程</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/sklearn/" style="font-size: 15px;">sklearn</a> <a href="/tags/easy/" style="font-size: 15px;">easy</a> <a href="/tags/BeautifulSoup/" style="font-size: 15px;">BeautifulSoup</a> <a href="/tags/分割/" style="font-size: 15px;">分割</a> <a href="/tags/可视化/" style="font-size: 15px;">可视化</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/Hbase/" style="font-size: 15px;">Hbase</a> <a href="/tags/Matlab/" style="font-size: 15px;">Matlab</a> <a href="/tags/R语言/" style="font-size: 15px;">R语言</a> <a href="/tags/无监督/" style="font-size: 15px;">无监督</a> <a href="/tags/GAN/" style="font-size: 15px;">GAN</a> <a href="/tags/监督学习/" style="font-size: 15px;">监督学习</a> <a href="/tags/数据挖掘/" style="font-size: 15px;">数据挖掘</a> <a href="/tags/py/" style="font-size: 15px;">py</a> <a href="/tags/数学/" style="font-size: 15px;">数学</a> <a href="/tags/word2vec/" style="font-size: 15px;">word2vec</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/sql/" style="font-size: 15px;">sql</a> <a href="/tags/matplotlib/" style="font-size: 15px;">matplotlib</a> <a href="/tags/Mysql/" style="font-size: 15px;">Mysql</a> <a href="/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/tags/numpy/" style="font-size: 15px;">numpy</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/http/" style="font-size: 15px;">http</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/05/31/use-gist/">use gist</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/25/CRFs-for-segmentation/">条件随机场用于语义分割</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/24/kullback-leibel-divergence/">KL散度</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/21/tensorflow-collection-and-scope/">tensorflow的collection和scope</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/18/python-oop/">python--面向对象编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/16/begining-gan/">Generative Adversarial Nets 对抗生成网络初探</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/16/semantic-segmentation-papers/">语义分割论文</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/11/git-branch-request/">gitlab分支管理</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/11/python-unittest/">python-unittest</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/10/tensorflow-model-restore-and-transfer/">TensorFlow的模型恢复与迁移</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://blog.csdn.net/u012925804" title="My CSDN" target="_blank">My CSDN</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">老姜工作室.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>